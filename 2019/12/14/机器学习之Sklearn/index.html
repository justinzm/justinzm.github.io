<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"justinzm.github.io","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Sklearn (全称 Scikit-Learn) 是基于 Python 语言的机器学习工具。它建立在 NumPy, SciPy, Pandas 和 Matplotlib 之上，里面的 API 的设计非常好，所有对象的接口简单，很适合新手上路。">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习之Sklearn">
<meta property="og:url" content="https://justinzm.github.io/2019/12/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSklearn/index.html">
<meta property="og:site_name" content="草根之明">
<meta property="og:description" content="Sklearn (全称 Scikit-Learn) 是基于 Python 语言的机器学习工具。它建立在 NumPy, SciPy, Pandas 和 Matplotlib 之上，里面的 API 的设计非常好，所有对象的接口简单，很适合新手上路。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://img.9lake.com/uPic/9NRoXM.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/lxUBeP.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/9BXoLs.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/Ztm9nF.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/cHnZTW.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/PkKSiH.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/N0yZnd.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/ggTLBd.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/60V2LY.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/Knzhdo.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/jeRRFB.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/ThUnLs.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/Rx6KAH.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/Pd3R9c.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/L5SyyT.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/4xkf68.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/JyJEKN.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/ucO1IA.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/K6gYLk.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/Wk40iH.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/I3W58A.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/WQkgZT.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/baMnJA.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/UMLsNX.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/z8o4Qx.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/tYvPFv.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/biWRkH.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/uub7kl.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/Po4pCQ.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/divLLr.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/dfCAgS.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/uFV0mx.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/mGgmL5.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/J3TQYX.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/o9FjM1.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/pPhE65.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/Pp9ZCS.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/LA2olY.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/VMzrvG.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/qbDoeq.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/7gM0cr.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/xnVNGW.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/qdEMHh.jpg">
<meta property="og:image" content="http://img.9lake.com/uPic/TDE8uM.jpg">
<meta property="article:published_time" content="2019-12-14T13:10:17.000Z">
<meta property="article:modified_time" content="2022-09-10T07:24:47.412Z">
<meta property="article:author" content="草根之明">
<meta property="article:tag" content="Sklearn">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://img.9lake.com/uPic/9NRoXM.jpg">

<link rel="canonical" href="https://justinzm.github.io/2019/12/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSklearn/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>机器学习之Sklearn | 草根之明</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">草根之明</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">管理及技术博客</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://justinzm.github.io/2019/12/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSklearn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="草根之明">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="草根之明">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习之Sklearn
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-14 21:10:17" itemprop="dateCreated datePublished" datetime="2019-12-14T21:10:17+08:00">2019-12-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-09-10 15:24:47" itemprop="dateModified" datetime="2022-09-10T15:24:47+08:00">2022-09-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Sklearn (全称 Scikit-Learn) 是基于 Python 语言的机器学习工具。它建立在 NumPy, SciPy, Pandas 和 Matplotlib 之上，里面的 API 的设计非常好，所有对象的接口简单，很适合新手上路。<span id="more"></span></p>
<p>在 Sklearn 里面有六大任务模块：分别是分类、回归、聚类、降维、模型选择和预处理，如下图从其官网的截屏。</p>
<p><img src="http://img.9lake.com/uPic/9NRoXM.jpg" alt="9NRoXM"></p>
<p>要使用上述六大模块的方法，可以用以下的伪代码，注意 import 后面我用的都是一些通用名称，如 SomeClassifier, SomeRegressor, SomeModel，具体化的名称由具体问题而定，比如</p>
<ul>
<li>SomeClassifier &#x3D; RandomForestClassifier</li>
<li>SomeRegressor &#x3D; LinearRegression</li>
<li>SomeModel &#x3D; KMeans, PCA</li>
<li>SomeModel &#x3D; GridSearchCV, OneHotEncoder</li>
</ul>
<p>上面具体化的例子分别是随机森林分类器、线性回归器、K 均值聚类、主成分分析、网格追踪法、独热编码。</p>
<h5 id="分类-Classification"><a href="#分类-Classification" class="headerlink" title="分类 (Classification)"></a>分类 (Classification)</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import SomeClassifier</span><br><span class="line">from sklearn.linear_model import SomeClassifier</span><br><span class="line">from sklearn.ensemble import SomeClassifier</span><br></pre></td></tr></table></figure>


<h5 id="回归-Regression"><a href="#回归-Regression" class="headerlink" title="回归 (Regression)"></a>回归 (Regression)</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import SomeRegressor</span><br><span class="line">from sklearn.linear_model import SomeRegressor</span><br><span class="line">from sklearn.ensemble import SomeRegressor</span><br></pre></td></tr></table></figure>


<h5 id="聚类-Clustering"><a href="#聚类-Clustering" class="headerlink" title="聚类 (Clustering)"></a>聚类 (Clustering)</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.cluster import SomeModel</span><br></pre></td></tr></table></figure>

<h5 id="降维-Dimensionality-Reduction"><a href="#降维-Dimensionality-Reduction" class="headerlink" title="降维 (Dimensionality Reduction)"></a>降维 (Dimensionality Reduction)</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.decomposition import SomeModel</span><br></pre></td></tr></table></figure>

<h5 id="模型选择-Model-Selection"><a href="#模型选择-Model-Selection" class="headerlink" title="模型选择 (Model Selection)"></a>模型选择 (Model Selection)</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import SomeModel</span><br></pre></td></tr></table></figure>

<h5 id="预处理-Preprocessing"><a href="#预处理-Preprocessing" class="headerlink" title="预处理 (Preprocessing)"></a>预处理 (Preprocessing)</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import SomeModel</span><br></pre></td></tr></table></figure>

<p>SomeClassifier, SomeRegressor, SomeModel 其实都叫做估计器 (estimator)，就像 Python 里「万物皆对象」那样，Sklearn 里「<strong>万物皆估计器</strong>」。</p>
<p>此外，Sklearn 里面还有很多自带数据集供，引入它们的伪代码如下。</p>
<h5 id="数据集-Dataset"><a href="#数据集-Dataset" class="headerlink" title="数据集 (Dataset)"></a>数据集 (Dataset)</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.datasets import SomeData</span><br></pre></td></tr></table></figure>

<p>本贴我们用以下思路来讲解：</p>
<ul>
<li>第一章介绍机器学习，从定义出发引出机器学习四要素：<strong>数据、任务、性能度量和模型</strong>。加这一章的原因是不把机器学习相关概念弄清楚之后很难完全弄明白 Sklearn。</li>
<li>第二章介绍 Sklearn，从其 API 设计原理出发分析其五大特点：<strong>一致性、可检验、标准类、可组合和默认值</strong>。最后再分析 Sklearn 里面自带数据以及储存格式。</li>
<li>第三章介绍 Sklearn 里面的三大核心 API，包括<strong>估计器、预测器和转换器</strong>。这一章的内容最重要，几乎所有模型都会用到这三大 API。</li>
<li>第四章介绍 Sklearn 里面的高级 API，即<strong>元估计器</strong>，有可以大大简化代码量的流水线 (Pipeline 估计器)，有集成模型 (Ensemble 估计器)、有多类别-多标签-多输出分类模型 (Multiclass 和 Multioutput 估计器) 和模型选择工具 (Model Selection 估计器)。</li>
</ul>
<h3 id="机器学习简介"><a href="#机器学习简介" class="headerlink" title="机器学习简介"></a>机器学习简介</h3><h4 id="定义和组成元素"><a href="#定义和组成元素" class="headerlink" title="定义和组成元素"></a>定义和组成元素</h4><p>什么是机器学习？字面上来讲就是 (人用) 计算机来学习。谈起机器学习就一定要提起汤姆米切尔 (Tom M.Mitchell)，就像谈起音乐就会提起贝多芬，谈起篮球就会提起迈克尔乔丹，谈起电影就会提起莱昂纳多迪卡普里奥。米切尔对机器学习定义的原话是：</p>
<pre><code>A computer program is said to learn from experience E with respect to some class of tasks  T and performance measure P if its performance at  tasks in T, as measured by P, improves with experience E.
</code></pre>
<p>整段英文有点抽象难懂对吗？首先注意到两个词 computer program 和 learn，翻译成中文就是机器 (计算机程序) 和学习，再把上面英译中：</p>
<pre><code>假设用性能度量 P 来评估机器在某类任务 T 的性能，若该机器通利用经验 E 在任务 T 中改善其性能 P，那么可以说机器对经验 E 进行了学习。
</code></pre>
<p>在该定义中，除了核心词机器和学习，还有关键词经验 E，性能度量 P 和任务 T。在计算机系统中，通常经验 E 是以数据 D 的形式存在，而机器学习就是给定不同的任务 T 从数据中产生模型 M，模型 M 的好坏就用性能度量 P 来评估。</p>
<p>由上述机器学习的定义可知机器学习包含四个元素</p>
<ul>
<li>数据 (Data)</li>
<li>任务 (Task)</li>
<li>性能度量 (Quality Metric)</li>
<li>模型 (Model)</li>
</ul>
<p><img src="http://img.9lake.com/uPic/lxUBeP.jpg" alt="lxUBeP"></p>
<p>下面四小节分别介绍数据、任务、性能度量和模型。</p>
<h4 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h4><p>数据 (data) 是经验的另一种说法，也是信息的载体。数据可分为</p>
<ul>
<li>结构化数据和非结构化数据 (按数据具体类型划分)</li>
<li>原始数据和加工数据 (按数据表达形式划分)</li>
<li>样本内数据和样本外数据 (按数据统计性质划分)</li>
</ul>
<h5 id="结构化和非结构化"><a href="#结构化和非结构化" class="headerlink" title="结构化和非结构化"></a>结构化和非结构化</h5><p>结构化数据 (structured data) 是由二维表结构来逻辑表达和实现的数据。非结构化数据是没有预定义的数据，不便用数据库二维表来表现的数据。</p>
<h6 id="非结构化数据"><a href="#非结构化数据" class="headerlink" title="非结构化数据"></a>非结构化数据</h6><p>非结构化数据包括图片，文字，语音和视屏等如下图。</p>
<p><img src="http://img.9lake.com/uPic/9BXoLs.jpg" alt="9BXoLs"></p>
<p>对于以上的非结构数据，相关应用实例有</p>
<ul>
<li>深度学习的卷积神经网络 (convolutional neural network, CNN) 对图像数据做人脸识别或物体分类</li>
<li>深度学习的循环神经网络 (recurrent neural network, RNN) 对语音数据做语音识别或机器对话，对文字数据做文本生成或阅读理解</li>
<li>增强学习的阿尔法狗 (AlphaGo) 对棋谱数据学习无数遍最终打败了围棋世界冠军李世石和柯洁</li>
</ul>
<p>计算机追根到底还是只能最有效率的处理数值型的结构化数据，如何从原始数据加工成计算机可应用的数据会在后面讲明。</p>
<h6 id="结构化数据"><a href="#结构化数据" class="headerlink" title="结构化数据"></a>结构化数据</h6><p>机器学习模型主要使用的是结构化数据，即二维的数据表。非结构化数据可以转换成结构化数据，比如把</p>
<ul>
<li>图像类数据里像素张量重塑成一维数组</li>
<li>文本类数据用独热编码转成二维数组</li>
</ul>
<p>对于结构化数据，我们用勒布朗詹姆斯 (Lebron James) 四场比赛的数据举例。</p>
<p><img src="http://img.9lake.com/uPic/Ztm9nF.jpg" alt="Ztm9nF"></p>
<p>下面术语大家在深入了解机器学习前一定要弄清楚：</p>
<ul>
<li>每行的记录 (这是一场比赛詹姆斯的个人统计) ，称为一个<strong>示例 (instance)</strong></li>
<li>反映对象在某方面的性质，例如得分，篮板，助攻，称为<strong>特征 (feature) 或输入 (input)</strong></li>
<li>特征上的取值，例如「示例 1」对应的 27, 10, 12 称为<strong>特征值 (feature value)</strong></li>
<li>关于示例结果的信息，例如赢，称为<strong>标签 (label) 或输出 (output)</strong></li>
<li>包含标签信息的示例，则称为**样例 (example)**，即样例 &#x3D; (特征, 标签)</li>
<li>从数据中学得模型的过程称为<strong>学习 (learning) 或训练 (training)</strong></li>
<li>在训练数据中，每个样例称为<strong>训练样例 (training example)<strong>，整个集合称为</strong>训练集 (training set)</strong></li>
</ul>
<h5 id="原始和加工"><a href="#原始和加工" class="headerlink" title="原始和加工"></a>原始和加工</h5><p>计算机处理数值型的结构型数据最有效率，但是现实世界到处出是原始数据，分为两类</p>
<ul>
<li>非结构数据比如图片和文字型数据 (情况一)</li>
<li>结构型数据的分类型变量 (情况二)</li>
</ul>
<h6 id="图像性数据"><a href="#图像性数据" class="headerlink" title="图像性数据"></a>图像性数据</h6><p>拿情况一的图片为例，通过特定函数 imread 将彩色图片用 RGB 像素表示出来，再按红绿蓝的顺序，将所有像素排成一个数值列向量 (column vector)，而计算机可以接受这样的输入。具体转换过程见下图。</p>
<p><img src="http://img.9lake.com/uPic/cHnZTW.jpg" alt="cHnZTW"></p>
<h6 id="文本型数据"><a href="#文本型数据" class="headerlink" title="文本型数据"></a>文本型数据</h6><p>推特 (twitter) 的每条推文 (tweet) 规定只能发 280 个字符。在编码推文时，将 280 个字符的序列用独热编码 (one-hot encoding) 到包含 128 个字符的 ASCII 表，如下所示。</p>
<p><img src="http://img.9lake.com/uPic/PkKSiH.jpg" alt="PkKSiH"></p>
<p>这样，每条推文都可以编码为 2 维张量形状 (280, 128)，比如一条 tweet 是 “I love python :)”，这句话映射到 ASCII 表变成：</p>
<p><img src="http://img.9lake.com/uPic/N0yZnd.jpg" alt="N0yZnd"></p>
<p>如果收集到 1 百万条推文，那么整个数据集的形状为 (1000000, 280, 128)。传统机器学习的对率回归可以来做情感分析。</p>
<h6 id="分类型变量"><a href="#分类型变量" class="headerlink" title="分类型变量"></a>分类型变量</h6><p>篮球比赛结果非输即赢，是一个二类 (binary class) 变量</p>
<p><img src="http://img.9lake.com/uPic/ggTLBd.jpg" alt="ggTLBd"></p>
<p>二类变量用「0-1编码」，比如比赛结果&#x3D; {赢, 输} 表示成 y&#x3D; [1 0 0 1]，1 代表赢，0 代表输。</p>
<p>而足球比赛结果是有赢、平、输三种，是一个多类 (multi-class) 变量。</p>
<p><img src="http://img.9lake.com/uPic/60V2LY.jpg" alt="60V2LY"></p>
<p>多类变量分别用 0, 1, 2 来表示，那么 y &#x3D; [0 1 0 2]。但更常见的是用独热编码 (one-hot encoding)，即</p>
<p><img src="http://img.9lake.com/uPic/Knzhdo.jpg" alt="Knzhdo"></p>
<h5 id="样本内和样本外"><a href="#样本内和样本外" class="headerlink" title="样本内和样本外"></a>样本内和样本外</h5><p>在统计中，把研究对象的全体称为总体 (population)，而把组成总体的各个元素称为个体，把从总体中抽取的若干个体称为样本 (sample)。</p>
<p><img src="http://img.9lake.com/uPic/jeRRFB.jpg" alt="jeRRFB"></p>
<p>举个调查中国男性平均身高的例子：</p>
<ul>
<li>全国的男性就是总体</li>
<li>每个男性是个体</li>
</ul>
<p>普查所有男性金钱花费和时间成本太高，通常会抽取若干男性作为样本，计算样本里的男性平均身高作为总体里的所有男性平均身高的推理 (inference)。</p>
<p>统计学中做的事情就是用样本数据的统计 (statistics) 来推出总体数据的参数 (parameter)。样本数据也叫做样本内数据，除样本内数据之外的总体数据叫做样本外数据。</p>
<p>在机器学习中，样本内和样本外数据的定义稍微有些不同，如下图：</p>
<p><img src="http://img.9lake.com/uPic/ThUnLs.jpg" alt="ThUnLs"></p>
<p><strong>样本内数据</strong>是用来训练模型的数据，也叫训练数据。它们是已知的，可计算统计的。</p>
<p><strong>样本外数据</strong>是未来的没见过的新数据。它们是未知的，不可计算统计的。</p>
<p>机器学习在样本内数据训练模型用来预测：</p>
<ul>
<li>样本内预测：根据训练模型对样本内数据进行预测，可与已知标签比较来评估模型表现</li>
<li>样本外预测：根据训练模型对样本外数据进行预测，不能与未知的标签比较</li>
</ul>
<p>机器学习的难点就是如何用好的样本内预测来保证好的样本外预测，幸运的是我们有〖计算学习理论〗来保证它。</p>
<h4 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h4><p>根据学习的任务模式 (训练数据是否有标签)，机器学习可分为四大类：</p>
<ul>
<li>有监督学习 (有标签)</li>
<li>无监督学习 (无标签)</li>
<li>半监督学习 (有部分标签)</li>
<li>增强学习 (有评级标签)</li>
</ul>
<p><strong>深度学习</strong>只是一种方法，而不是任务模式，因此与上面四类不属于同一个维度，但是深度学习与它们可以叠加成：深度有监督学习、深度非监督学习、深度半监督学习和深度增强学习。迁移学习也是一种方法，也可以分类为有监督迁移学习、非监督迁移学习、半监督迁移学习和增强迁移学习。</p>
<p>下图画出机器学习各类之间的关系。</p>
<p><img src="http://img.9lake.com/uPic/Rx6KAH.jpg" alt="Rx6KAH"></p>
<p>由于 Sklearn 里面模型主要处理「有监督学习」和「无监督学习」两类，我们接下来也只讨论这两类。</p>
<h5 id="有监督学习"><a href="#有监督学习" class="headerlink" title="有监督学习"></a>有监督学习</h5><p>有监督学习 (supervised learning) 利用输入数据及其对应标签来训练模型。这种学习方法类似学生通过研究问题和参考答案来学习，在掌握问题和答案之间的对应关系后，学生可自己给出相似新问题的答案了。</p>
<p>在有监督学习中，数据 &#x3D; (<strong>特征，标签</strong>)，而其主要任务是分类和回归。以上述詹姆斯的个人统计为例。</p>
<h6 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h6><p>如果预测的是离散值 (discrete value)，例如比赛结果赢或输，此类学习任务称为分类 (classification)。</p>
<p><img src="http://img.9lake.com/uPic/Pd3R9c.jpg" alt="Pd3R9c"></p>
<h6 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h6><p>如果预测的是连续值 (continuous value)，例如詹姆斯效率 65.1, 70.3 等等，此类学习任务称为回归 (regression)。</p>
<p><img src="http://img.9lake.com/uPic/L5SyyT.jpg" alt="L5SyyT"></p>
<h5 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h5><p>无监督学习 (unsupervised learning) 是找出输入数据的模式。比如，它可以根据电影的各种特征做聚类，用这种方法收集数据为电影推荐系统提供标签。此外无监督学习还可以降低数据的维度，它可以帮助我们更好的理解数据。</p>
<p>在无监督学习中，数据 &#x3D; (<strong>特征，</strong>)。</p>
<h6 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h6><p>除了根据詹姆斯个人统计来预测骑士队输赢或者个人效率值外，我们还可以对该数据做聚类 (clustering)，即将训练集中的数据分成若干组，每组成为一个簇 (cluster)。</p>
<p><img src="http://img.9lake.com/uPic/4xkf68.jpg" alt="4xkf68"></p>
<p>假设聚类方法将数据聚成二个簇 A 和 B，如下图</p>
<p><img src="http://img.9lake.com/uPic/JyJEKN.jpg" alt="JyJEKN"></p>
<p>后来发现簇 A 代表赢，簇 B 代表输。聚类的用处就是可以找到一个潜在的原因来解释为什么样例 1 和 3 可以赢球。难道真的是只要詹姆斯三双就可以赢球？</p>
<h6 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h6><p>注：下面对降维的理解不是那么严谨，只为了让小白对降维大概有个概念。</p>
<p>詹姆斯完整统计数据还有抢断、盖帽和犯规，但这些对预测比赛输赢、效率值都没什么用，因此可以通过降维的方法将其去除。</p>
<p><img src="http://img.9lake.com/uPic/ucO1IA.jpg" alt="ucO1IA"></p>
<h4 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h4><p>回归和分类任务中最常见的误差函数以及一些有用的性能度量如下。</p>
<p><img src="http://img.9lake.com/uPic/K6gYLk.jpg" alt="K6gYLk"></p>
<p>回归任务的误差函数估量在数据集 D 上模型的连续型预测值 h(x) 与连续型真实值 y 的距离，h(x) 和 y 可以取任意实数。误差函数是一个非负实值函数，通常使用 ED[h] 来表示。图表展示如下。</p>
<p><img src="http://img.9lake.com/uPic/Wk40iH.jpg" alt="Wk40iH"></p>
<p><img src="http://img.9lake.com/uPic/I3W58A.jpg" alt="I3W58A"></p>
<p>分类任务的误差函数估量在数据集 D 上模型的离散型预测值 h(x) 与离散型真实值 y 的不一致程度，惯例是 y 和 h(x) 取±1，比如正类取 1 负类取 -1。图表展示如下。</p>
<p><img src="http://img.9lake.com/uPic/WQkgZT.jpg" alt="WQkgZT"></p>
<p><img src="http://img.9lake.com/uPic/baMnJA.jpg" alt="baMnJA"></p>
<p>除上述损失函数之外，分类任务还有很多其他有用的性能度量。</p>
<p><strong>错误率：</strong>分类错误的样本数占样本总数的比例称为错误率 (error rate)，相应的分类正确的样本数占样本总数的比例称为精度 (accuracy)。在 10 个样本中有 2 个样本分类错误，则错误率为 20%，而精度为 80%。</p>
<p><strong>查准率和查全率：</strong>错误率和精度虽然常用，但是不能满足所有任务需求。假定用训练好的模型预测骑士赢球，显然，错误率衡量了多少比赛实际是赢球但预测成输球。但是若我们关心的是“预测出的比赛中有多少是赢球”，或“赢球的比赛中有多少被预测出了”，那么错误率这个单一指标显然就不够用了，这时需要引进更为细分的性能度量，即查准率 (precision) 和查全率 (recall)。</p>
<p>其他概念比如混淆矩阵、ROC、AUC 我们再下帖的实例用到时再细讲。</p>
<h4 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h4><p>有监督模型如下图所示：</p>
<p><img src="http://img.9lake.com/uPic/UMLsNX.jpg" alt="UMLsNX"></p>
<p>无监督模型包括各种聚类分析 (KMeans, DBSCAN)、主成分分析 (PCA)、独立成分分析 (ICA)、隐含狄利克雷分配 (LDA) 等等。</p>
<h3 id="Sklearn-数据"><a href="#Sklearn-数据" class="headerlink" title="Sklearn 数据"></a>Sklearn 数据</h3><p>Sklearn 和之前讨论的 NumPy, SciPy, Pandas, Matplotlib 相似，就是一个处理特殊任务的包，Sklearn 就是处理机器学习 (有监督学习和无监督学习) 的包，更精确的说，它里面有六个任务模块和一个数据引入模块：</p>
<ul>
<li>有监督学习的<strong>分类任务</strong></li>
<li>有监督学习的<strong>回归任务</strong></li>
<li>无监督学习的<strong>聚类任务</strong></li>
<li>无监督学习的<strong>降维任务</strong></li>
<li><strong>数据预处理任务</strong></li>
<li><strong>模型选择任务</strong></li>
<li>数据引入</li>
</ul>
<p>本节就来看看 Sklearn 里数据格式和自带数据集。</p>
<h4 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h4><p>在 Sklean 里，模型能即用的数据有两种形式：</p>
<ol>
<li>Numpy 二维数组 (ndarray) 的稠密数据 (dense data)，通常都是这种格式。</li>
<li>SciPy 矩阵 (scipy.sparse.matrix) 的稀疏数据 (sparse data)，比如文本分析每个单词 (字典有 100000 个词) 做独热编码得到矩阵有很多 0，这时用 ndarray 就不合适了，太耗内存。</li>
</ol>
<p>上述数据在机器学习中通常用符号 X 表示，是模型自变量。它的大小 &#x3D; [样本数, 特征数]，图下图所示。该房屋数据有 21000 条包括平方英尺，卧室数，楼层，日期，翻新年份等等 21 栏。该数据形状为 [21000, 21]</p>
<p><img src="http://img.9lake.com/uPic/z8o4Qx.jpg" alt="z8o4Qx"></p>
<p>有监督学习除了需要特征 X 还需要标签 y，而 y 通常就是 Numpy 一维数组，无监督学习没有 y。</p>
<h4 id="自带数据集"><a href="#自带数据集" class="headerlink" title="自带数据集"></a>自带数据集</h4><p>Sklearn 里面有很多自带数据集供用户使用。</p>
<h5 id="特例描述"><a href="#特例描述" class="headerlink" title="特例描述"></a>特例描述</h5><p><img src="http://img.9lake.com/uPic/tYvPFv.jpg" alt="tYvPFv"></p>
<p>数据集包括 150 条鸢尾花的四个特征 (萼片长&#x2F;宽和花瓣长&#x2F;宽) 和三个类别。从 Sklearn 里面的 datasets 模块中引入，代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">iris = load_iris()</span><br></pre></td></tr></table></figure>

<p>数据是以「字典」格式存储的，看看 iris 的键有哪些。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">iris.keys()</span><br><span class="line"></span><br><span class="line">dict_keys([&#x27;data&#x27;, &#x27;target&#x27;,</span><br><span class="line">           &#x27;target_names&#x27;, &#x27;DESCR&#x27;,</span><br><span class="line">           &#x27;feature_names&#x27;, &#x27;filename&#x27;])</span><br></pre></td></tr></table></figure>

<p>键里面的名称解释如下：</p>
<ul>
<li>data：特征值 (数组)</li>
<li>target：标签值 (数组)</li>
<li>target_names：标签 (列表)</li>
<li>DESCR：数据集描述</li>
<li>feature_names：特征 (列表)</li>
<li>filename：iris.csv 文件路径</li>
</ul>
<p>具体感受一下 iris 数据中特征的大小、名称和前五个示例。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">n_samples, n_features = iris.data.shape</span><br><span class="line">print((n_samples, n_features))</span><br><span class="line">print(iris.feature_names)</span><br><span class="line">iris.data[0:5]</span><br><span class="line"></span><br><span class="line">(150, 4)</span><br><span class="line"></span><br><span class="line">[&#x27;sepal length (cm)&#x27;, &#x27;sepal width (cm)&#x27;,</span><br><span class="line"> &#x27;petal length (cm)&#x27;, &#x27;petal width (cm)&#x27;]</span><br><span class="line"></span><br><span class="line">array([[5.1, 3.5, 1.4, 0.2],</span><br><span class="line">       [4.9, 3. , 1.4, 0.2],</span><br><span class="line">       [4.7, 3.2, 1.3, 0.2],</span><br><span class="line">       [4.6, 3.1, 1.5, 0.2],</span><br><span class="line">       [5. , 3.6, 1.4, 0.2]])</span><br></pre></td></tr></table></figure>



<p>150 个样本，4 个特征，没毛病！再感受一下标签的大小、名称和全部示例。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">print(iris.target.shape)</span><br><span class="line">print(iris.target_names)</span><br><span class="line">iris.target</span><br><span class="line"></span><br><span class="line">(150,)</span><br><span class="line"></span><br><span class="line">[&#x27;setosa&#x27; &#x27;versicolor&#x27; &#x27;virginica&#x27;]</span><br><span class="line"></span><br><span class="line">array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span><br><span class="line">       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span><br><span class="line">       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span><br><span class="line">       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span><br><span class="line">       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,</span><br><span class="line">       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,</span><br><span class="line">       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])</span><br></pre></td></tr></table></figure>

<p>150 个标签，3 类别 (分别用 0, 1, 2 数值来代表 setosa, versicolor, virginica)。</p>
<p>用 Pandas 的 DataFrame (将 X 和 y 合并) 和 Seaborn 的 pairplot (看每个特征之间的关系) 来用表格和图来展示一下数据集的内容。</p>
<h6 id="Pandas-DataFrame"><a href="#Pandas-DataFrame" class="headerlink" title="Pandas DataFrame"></a>Pandas DataFrame</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">iris_data = pd.DataFrame( iris.data, </span><br><span class="line">                          columns=iris.feature_names )</span><br><span class="line">iris_data[&#x27;species&#x27;] = iris.target_names[iris.target]</span><br><span class="line">iris_data.head(3).append(iris_data.tail(3))</span><br></pre></td></tr></table></figure>

<h6 id="Seaborn-Pairplot"><a href="#Seaborn-Pairplot" class="headerlink" title="Seaborn Pairplot"></a>Seaborn Pairplot</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.pairplot( iris_data, hue=&#x27;species&#x27;, palette=&#x27;husl&#x27; );</span><br></pre></td></tr></table></figure>

<p><img src="http://img.9lake.com/uPic/biWRkH.jpg" alt="biWRkH"></p>
<h5 id="正规引入"><a href="#正规引入" class="headerlink" title="正规引入"></a>正规引入</h5><p>看完鸢尾花的 iris 数据展示后，现在来看看 Sklearn 三种引入数据形式。</p>
<ul>
<li>打包好的数据：对于小数据集，用 sklearn.datasets.load_*</li>
<li>分流下载数据：对于大数据集，用 sklearn.datasets.fetch_*</li>
<li>随机创建数据：为了快速展示，用 sklearn.datasets.make_*</li>
</ul>
<p>上面这个星号 * 是什么意思，指的是具体文件名，敲完</p>
<ul>
<li>datasets.load_<TAB></li>
<li>datasets.fetch_<TAB></li>
<li>datasets.make_<TAB></li>
</ul>
<p>点击键盘上的 <TAB> 键就可以看到很多完整的文件名，看下面动图就明白了。</p>
<p><img src="http://img.9lake.com/uPic/uub7kl.jpg" alt="uub7kl"></p>
<p>Load 一个数字小数据集 digits?</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">digits = datasets.load_digits()</span><br><span class="line">digits.keys()</span><br><span class="line">dict_keys([&#x27;data&#x27;, &#x27;target&#x27;, &#x27;target_names&#x27;,</span><br><span class="line">           &#x27;images&#x27;, &#x27;DESCR&#x27;])</span><br></pre></td></tr></table></figure>



<p>Fetch 一个加州房屋大数据集 california_housing?</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">california_housing = datasets.fetch_california_housing()</span><br><span class="line">california_housing.keys()</span><br><span class="line">dict_keys([&#x27;data&#x27;, &#x27;target&#x27;,</span><br><span class="line">           &#x27;feature_names&#x27;, &#x27;DESCR&#x27;])</span><br></pre></td></tr></table></figure>

<p>Make 一个高斯分位数数据集 gaussian_quantile？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gaussian_quantiles = datasets.make_gaussian_quantiles()</span><br><span class="line">type(gaussian_quantiles), len(gaussian_quantiles)</span><br><span class="line">(tuple, 2)</span><br></pre></td></tr></table></figure>

<p>好了，本节讲的就是通过 sklearn 获得数据三种方式。在自己做数据分析时，最常见的还是从 csv 和 txt 文件中通过 Pandas 读取并存储成 DataFrame 的形式。</p>
<h3 id="核心-API"><a href="#核心-API" class="headerlink" title="核心 API"></a>核心 API</h3><p>Sklearn 里万物皆估计器。估计器是个非常抽象的叫法，可把它不严谨的当成一个模型 (用来回归、分类、聚类、降维)，或当成一套流程 (预处理、网格最终)。</p>
<p>本节三大 API 其实都是估计器：</p>
<ol>
<li>估计器 (estimator) 当然是<strong>估计器</strong></li>
<li>预测器 (predictor) 是<strong>具有预测功能的估计器</strong></li>
<li>转换器 (transformer) 是<strong>具有转换功能的估计器</strong></li>
</ol>
<p>这三句看似废话，其实蕴藏了很多内容。其实我对第 1 点这个估计器的起名不太满意，我觉得应该叫拟合器 (fitter) - 具有拟合功能的估计器。看完这一节你就会明白「拟合器」这种叫法更合理。</p>
<h4 id="估计器"><a href="#估计器" class="headerlink" title="估计器"></a>估计器</h4><p><strong>定义：任何可以基于数据集对一些参数进行估计的对象都被称为估计器。</strong></p>
<p>两个核心点：<strong>1. 需要输入数据，2. 可以估计参数</strong>。估计器首先被创建，然后被拟合。</p>
<p>创建估计器</p>
<pre><code>创建估计器：需要设置一组超参数，比如

- 线性回归里超参数 normalize=True
- K 均值里超参数 n_clusters=3

在创建好的估计器 model 可以直接访问这些超参数，用 . 符号。

- model.normalize
- model.n_clusters

但 model 中有很多超参数，你不可能一开始都知道要设置什么值，没设置的用 Sklearn 会给个合理的默认值，因此新手不用担心。
</code></pre>
<p>拟合估计器</p>
<pre><code>拟合估计器：需要训练集。在有监督学习中的代码范式为

    model.fit( X_train, y_train )

在无监督学习中的代码范式为

    model.fit( X_train )

拟合之后可以访问 model 里学到的参数，比如线性回归里的特征前的系数 coef_，或 K 均值里聚类标签 labels_。

- model.coef_
- model.labels_
</code></pre>
<p>说了这么多抽象的东西，现在展示有监督学习的「线性回归」和无监督学习的「K 均值」的具体例子。</p>
<h5 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h5><p>首先从 sklearn 下的 linear_model 中引入 LinearRegression，再创建估计器起名 model，设置超参数 normalize 为 True，指的在每个特征值上做标准化，这样会加速数值运算。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"></span><br><span class="line">model = LinearRegression(normalize=True)</span><br><span class="line">model</span><br></pre></td></tr></table></figure>

<p><img src="http://img.9lake.com/uPic/Po4pCQ.jpg" alt="Po4pCQ"></p>
<p>创建完后的估计器会显示所有的超参数，比如我们设置好的 normalize&#x3D;True，其他没设置的都是去默认值，比如 n_jobs&#x3D;None 是只用一个核，你可以将其设为 2 就是两核并行，甚至设为 -1 就是电脑里所有核并行。</p>
<p>自己创建一个简单数据集 (没有噪声完全线性) 只为了讲解估计器里面的特征。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = np.arange(10)</span><br><span class="line">y = 2 * x + 1</span><br><span class="line">plt.plot( x, y, &#x27;o&#x27; );</span><br></pre></td></tr></table></figure>

<p><img src="http://img.9lake.com/uPic/divLLr.jpg" alt="divLLr"></p>
<p>还记得 Sklearn 里模型要求特征 X 是个两维变量么 (样本数×特征数)？但在本例中 X 是一维，因为我们用 np.newaxis 加一个维度，它做的事情就是把 [1, 2, 3] 转成 [[1],[2],[3]]。再把 X 和 y 丢进 fit() 函数来拟合线性模型的参数。</p>
<p>X &#x3D; x[:, np.newaxis]<br>model.fit( X, y )</p>
<p>拟合完后的估计器和创建完的样子看起来一样，但是已经用「model.param_」可以访问到学好的参数了，展示如下。</p>
<p>print( model.coef_ )<br>print( model.intercept_ )<br>[2.]<br>1.0</p>
<p>斜率为 2，截距为 1，没毛病。和访问超参数时不一样，注意访问参数要加一个下划线 _。</p>
<h5 id="K-均值"><a href="#K-均值" class="headerlink" title="K 均值"></a>K 均值</h5><p>首先从 sklearn 下的 cluster 中引入 KMeans，再创建估计器起名 model，设置超参数 n_cluster 为 3 (为了展示方便而我们知道用的 iris 数据集有 3 类，实际上应该选不同数量的 n_cluster，根据 elbow 图来决定，下帖细讲)。</p>
<p>再者，iris 数据里是有标签 y 的，我们假装没有 y 才能无监督的聚类啊，要不然应该做有监督的分类的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.cluster import KMeans</span><br><span class="line"></span><br><span class="line">model = KMeans( n_clusters=3 )</span><br><span class="line">model</span><br></pre></td></tr></table></figure>

<p><img src="http://img.9lake.com/uPic/dfCAgS.jpg" alt="dfCAgS"></p>
<p>创建完后的估计器会显示所有的超参数，比如我们设置好的 n_cluster&#x3D;3，其他没设置的都是去默认值，比如 max_iter&#x3D;300 是最多迭代次数为 300，算法不收敛也停了。</p>
<p>还记得 iris 里的特征有四个吗 (萼片长、萼片宽、花瓣长、花瓣宽)？四维特征很难可视化，因此我们只取两个特征 (萼片长、萼片宽) 来做聚类并且可视化结果。注意下面代码 X &#x3D; iris.data[:,0:2]。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = iris.data[:,0:2]</span><br><span class="line">model.fit(X)</span><br></pre></td></tr></table></figure>

<p><img src="http://img.9lake.com/uPic/uFV0mx.jpg" alt="uFV0mx"></p>
<p>拟合完后的估计器和创建完的样子看起来一样，但是已经用「model.param_」可以访问到学好的参数了，展示如下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print( model.cluster_centers_, &#x27;\n&#x27;)</span><br><span class="line">print( model.labels_, &#x27;\n&#x27; )</span><br><span class="line">print( model.inertia_, &#x27;\n&#x27;)</span><br><span class="line">print( iris.target )</span><br></pre></td></tr></table></figure>

<p><img src="http://img.9lake.com/uPic/mGgmL5.jpg" alt="mGgmL5"></p>
<p>有点乱，解释一下 KMeans 模型这几个参数：</p>
<ul>
<li>model.cluster_centers_：簇中心。三个簇那么有三个坐标。</li>
<li>model.labels_：聚类后的标签</li>
<li>model.inertia_：所有点到对应的簇中心的距离平方和 (越小越好)</li>
</ul>
<p>需要强调的是真实标签 iris.label 和聚类标签 model.labels_ 看起来差的很远。类别 0 都一致，但是类别 1 和 2 弄反了，这是因为在 KMeans 算法里标注的类别索引和真实类别索引不一样 (我现在也没找到什么方法能够让它们一致)。</p>
<p>最后画出两幅图，左图是根据聚类得到的标签画出散点图，而右图是根据真实标签画出散点图，对比两幅图看很像，聚类的效果还不错是把。</p>
<p><img src="http://img.9lake.com/uPic/J3TQYX.jpg" alt="J3TQYX"></p>
<p><img src="http://img.9lake.com/uPic/o9FjM1.jpg" alt="o9FjM1"></p>
<h5 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h5><p>虽然上面以有监督学习的 LinearRegression 和无监督学习的 KMeans 举例，但实际上你可以将它们替换成其他别的模型，比如有监督学习的 LogisticRegression 和无监督学习的 DBSCAN。它们都是「估计器」，因此都有 fit() 方法。使用它们的通用伪代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 有监督学习</span><br><span class="line">from sklearn.xxx import SomeModel</span><br><span class="line"># xxx 可以是 linear_model 或 ensemble 等</span><br><span class="line"></span><br><span class="line">model = SomeModel( hyperparameter )</span><br><span class="line">model.fit( X, y )</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 无监督学习</span><br><span class="line">from sklearn.xxx import SomeModel</span><br><span class="line"># xxx 可以是 cluster 或 decomposition 等</span><br><span class="line"></span><br><span class="line">model = SomeModel( hyperparameter )</span><br><span class="line">model.fit( X )</span><br></pre></td></tr></table></figure>

<h4 id="预测器"><a href="#预测器" class="headerlink" title="预测器"></a>预测器</h4><p><strong>定义：预测器在估计器上做了一个延展，延展出预测的功能。</strong></p>
<p>两个核心点：<strong>1. 基于学到的参数预测，2. 预测有很多指标</strong>。最常见的就是 predict() 函数：</p>
<p>model.predict(X_test)：<strong>评估</strong>模型在新数据上的表现</p>
<p>model.predict(X_train)：<strong>确认</strong>模型在老数据上的表现</p>
<p>因为要做预测，首先将数据分成 80:20 的训练集 (X_train, y_train) 和测试集 (X_test, y_test)，在用从训练集上拟合 fit() 的模型在测试集上预测 predict()。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">iris = load_iris()</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test </span><br><span class="line">= train_test_split( iris[&#x27;data&#x27;], </span><br><span class="line">                    iris[&#x27;target&#x27;], </span><br><span class="line">                    test_size=0.2 )</span><br><span class="line"></span><br><span class="line">print( &#x27;The size of X_train is &#x27;, X_train.shape )</span><br><span class="line">print( &#x27;The size of y_train is &#x27;, y_train.shape )</span><br><span class="line">print( &#x27;The size of X_test is &#x27;, X_test.shape )</span><br><span class="line">print( &#x27;The size of y_test is &#x27;, y_test.shape )</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">The size of X_train is (120, 4)</span><br><span class="line">The size of y_train is (120,)</span><br><span class="line">The size of X_test is (30, 4)</span><br><span class="line">The size of y_test is (30,)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>让我们来看个有监督学习的「对率回归」和继续上节无监督学习的「K 均值」的例子。</p>
<h5 id="对率回归"><a href="#对率回归" class="headerlink" title="对率回归"></a>对率回归</h5><p>首先从 sklearn 下的 linear_model 中引入 LogisticRegression，再创建估计器起名 model，设置超参数 mutli_class 为 multinomial 因为有三种鸢尾花，是个多分类问题。</p>
<p>接着再训练集上拟合参数，这时估计器 model 里面已经可以访问这些参数了。</p>
<p><img src="http://img.9lake.com/uPic/pPhE65.jpg" alt="pPhE65"></p>
<p><img src="http://img.9lake.com/uPic/Pp9ZCS.jpg" alt="Pp9ZCS"></p>
<p><strong>predict &amp; predict_proba</strong></p>
<p>对于分类问题，我们不仅想知道预测的类别是什么，有时还想知道预测该类别的信心如何。前者用 predict()，后者用 predict_proba()。</p>
<p>代码如下，在测试集上比较预测标签 y_pred 和真实标签 y_test 发现它们完全吻合，准确率 100% (iris 数据太简单 )。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">y_pred = model.predict( X_test )</span><br><span class="line">p_pred = model.predict_proba( X_test )</span><br><span class="line">print( y_test, &#x27;\n&#x27; )</span><br><span class="line">print( y_pred, &#x27;\n&#x27; )</span><br><span class="line">print( p_pred )</span><br></pre></td></tr></table></figure>

<p><img src="http://img.9lake.com/uPic/LA2olY.jpg" alt="LA2olY"></p>
<p>解释一下 p_pred - 测试集里有 30 个数据，鸢尾花有 3 类，因此 predict_proba() 生成一个 30×3 的数组，每行的概率加起来为 1。</p>
<p>为了验证我们的理解，我们看 Sklearn 是不是把「每行中最大概率值对应的那一类」作为预测结果。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s = [&#x27;Class 1 Prob&#x27;, &#x27;Class 2 Prob&#x27;, &#x27;Class 3 Prob&#x27;]</span><br><span class="line">prob_DF = pd.DataFrame( p_pred, columns=s )</span><br><span class="line">prob_DF[&#x27;Predicted Class&#x27;] = y_pred</span><br><span class="line">prob_DF.head()</span><br></pre></td></tr></table></figure>

<p><img src="http://img.9lake.com/uPic/VMzrvG.jpg" alt="VMzrvG"></p>
<p>是的！前三行 Class 1 Prob 最大，预测是第一类；第四行 Class 2 Prob 最大，预测是第二类；第四行 Class 3 Prob 最大，预测是第三类。</p>
<p><strong>score &amp; decision_function</strong></p>
<p>预测器里还有额外的两个函数可以使用。在分类问题中</p>
<ul>
<li>score() 返回的是分类准确率</li>
<li>decision_function() 返回的是每个样例在每个类下的分数值</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print( model.score( X_test, y_test ) )</span><br><span class="line">print( np.sum(y_pred==y_test)/len(y_test) )</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.0</span><br><span class="line">1.0</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">decision_score = model.decision_function( X_test )</span><br><span class="line">print( decision_score )</span><br></pre></td></tr></table></figure>

<p><img src="http://img.9lake.com/uPic/qbDoeq.jpg" alt="qbDoeq"></p>
<p>为了验证我们的理解，我们看 Sklearn 是不是把「每行中最高得分值对应的那一类」作为预测结果。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s = [&#x27;Class 1 Score&#x27;, &#x27;Class 2 Score&#x27;, &#x27;Class 3 Score&#x27;]</span><br><span class="line">decision_DF = pd.DataFrame( decision_score, columns=s )</span><br><span class="line">decision_DF[&#x27;Predicted Class&#x27;] = y_pred</span><br><span class="line">decision_DF.tail()</span><br></pre></td></tr></table></figure>

<p><img src="http://img.9lake.com/uPic/7gM0cr.jpg" alt="7gM0cr"></p>
<p>是的！前两行 Class 3 Score 最大，预测是第三类；后三行 Class 1 Score 最大，预测是第一类。</p>
<h5 id="K-均值-1"><a href="#K-均值-1" class="headerlink" title="K 均值"></a>K 均值</h5><p>继续上一节的 KMeans 模型，首先用 fit() 训练。</p>
<p><img src="http://img.9lake.com/uPic/xnVNGW.jpg" alt="xnVNGW"></p>
<p>再用 predict() 在测试集上预测出类别 inx_pred，和真实标签 y_test 比对。再次强调，inx_pred 和 y_test 给三个类别的索引定义是不同的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">idx_pred = model.predict( X_test[:,0:2] )</span><br><span class="line">print( index_pred )</span><br><span class="line">print( y_test )</span><br></pre></td></tr></table></figure>

<p>最后画出两幅图 (都是在测试集上)，左图是根据聚类预测的标签画出散点图，而右图是根据真实标签画出散点图，对比两幅图看很像，聚类的效果也不错。</p>
<p><img src="http://img.9lake.com/uPic/qdEMHh.jpg" alt="qdEMHh"></p>
<p><img src="http://img.9lake.com/uPic/TDE8uM.jpg" alt="TDE8uM"></p>
<p>KMeans 模型里也有 score() 函数，输出是值是它要优化的目标函数的对数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.score( X_test[:,0:2] )</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-9.662259042197803</span><br></pre></td></tr></table></figure>

<h5 id="小节"><a href="#小节" class="headerlink" title="小节"></a>小节</h5><p>估计器都有 fit() 方法，预测器都有 predict() 和 score() 方法，言外之意不是每个预测器都有 predict_proba() 和 decision_function() 方法，这个在用的时候查查官方文档就清楚了 (比如 RandomForestClassifier 就没有 decision_function() 方法)。</p>
<p>使用它们的通用伪代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 有监督学习</span><br><span class="line">from sklearn.xxx import SomeModel</span><br><span class="line"># xxx 可以是 linear_model 或 ensemble 等</span><br><span class="line"></span><br><span class="line">model = SomeModel( hyperparameter )</span><br><span class="line">model.fit( X, y )</span><br><span class="line">y_pred = model.predict( X_new )</span><br><span class="line">s = model.score( X_new )</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 无监督学习</span><br><span class="line">from sklearn.xxx import SomeModel</span><br><span class="line"># xxx 可以是 cluster 或 decomposition 等</span><br><span class="line"></span><br><span class="line">model = SomeModel( hyperparameter )</span><br><span class="line">model.fit( X )</span><br><span class="line">idx_pred = model.predict( X_new )</span><br><span class="line">s = model.score( X_new )</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Sklearn/" rel="tag"># Sklearn</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/10/31/%CE%B1%E7%9A%84%E4%B8%89%E8%A6%81%E7%B4%A0/" rel="prev" title="α的三要素">
      <i class="fa fa-chevron-left"></i> α的三要素
    </a></div>
      <div class="post-nav-item">
    <a href="/2019/12/15/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8BPandas/" rel="next" title="数据结构之Pandas">
      数据结构之Pandas <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%86%E7%B1%BB-Classification"><span class="nav-number">1.</span> <span class="nav-text">分类 (Classification)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9B%9E%E5%BD%92-Regression"><span class="nav-number">2.</span> <span class="nav-text">回归 (Regression)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%81%9A%E7%B1%BB-Clustering"><span class="nav-number">3.</span> <span class="nav-text">聚类 (Clustering)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%99%8D%E7%BB%B4-Dimensionality-Reduction"><span class="nav-number">4.</span> <span class="nav-text">降维 (Dimensionality Reduction)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9-Model-Selection"><span class="nav-number">5.</span> <span class="nav-text">模型选择 (Model Selection)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%A2%84%E5%A4%84%E7%90%86-Preprocessing"><span class="nav-number">6.</span> <span class="nav-text">预处理 (Preprocessing)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86-Dataset"><span class="nav-number">7.</span> <span class="nav-text">数据集 (Dataset)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B"><span class="nav-number"></span> <span class="nav-text">机器学习简介</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E5%92%8C%E7%BB%84%E6%88%90%E5%85%83%E7%B4%A0"><span class="nav-number"></span> <span class="nav-text">定义和组成元素</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE"><span class="nav-number"></span> <span class="nav-text">数据</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%BB%93%E6%9E%84%E5%8C%96%E5%92%8C%E9%9D%9E%E7%BB%93%E6%9E%84%E5%8C%96"><span class="nav-number">1.</span> <span class="nav-text">结构化和非结构化</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E9%9D%9E%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE"><span class="nav-number">1.1.</span> <span class="nav-text">非结构化数据</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE"><span class="nav-number">1.2.</span> <span class="nav-text">结构化数据</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8E%9F%E5%A7%8B%E5%92%8C%E5%8A%A0%E5%B7%A5"><span class="nav-number">2.</span> <span class="nav-text">原始和加工</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E6%80%A7%E6%95%B0%E6%8D%AE"><span class="nav-number">2.1.</span> <span class="nav-text">图像性数据</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%96%87%E6%9C%AC%E5%9E%8B%E6%95%B0%E6%8D%AE"><span class="nav-number">2.2.</span> <span class="nav-text">文本型数据</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E5%9E%8B%E5%8F%98%E9%87%8F"><span class="nav-number">2.3.</span> <span class="nav-text">分类型变量</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A0%B7%E6%9C%AC%E5%86%85%E5%92%8C%E6%A0%B7%E6%9C%AC%E5%A4%96"><span class="nav-number">3.</span> <span class="nav-text">样本内和样本外</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%BB%E5%8A%A1"><span class="nav-number"></span> <span class="nav-text">任务</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.</span> <span class="nav-text">有监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%88%86%E7%B1%BB"><span class="nav-number">1.1.</span> <span class="nav-text">分类</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%9B%9E%E5%BD%92"><span class="nav-number">1.2.</span> <span class="nav-text">回归</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-number">2.</span> <span class="nav-text">无监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E8%81%9A%E7%B1%BB"><span class="nav-number">2.1.</span> <span class="nav-text">聚类</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E9%99%8D%E7%BB%B4"><span class="nav-number">2.2.</span> <span class="nav-text">降维</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E5%BA%A6%E9%87%8F"><span class="nav-number"></span> <span class="nav-text">性能度量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B"><span class="nav-number"></span> <span class="nav-text">模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sklearn-%E6%95%B0%E6%8D%AE"><span class="nav-number"></span> <span class="nav-text">Sklearn 数据</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F"><span class="nav-number"></span> <span class="nav-text">数据格式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%B8%A6%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number"></span> <span class="nav-text">自带数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%89%B9%E4%BE%8B%E6%8F%8F%E8%BF%B0"><span class="nav-number">1.</span> <span class="nav-text">特例描述</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Pandas-DataFrame"><span class="nav-number">1.1.</span> <span class="nav-text">Pandas DataFrame</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Seaborn-Pairplot"><span class="nav-number">1.2.</span> <span class="nav-text">Seaborn Pairplot</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%AD%A3%E8%A7%84%E5%BC%95%E5%85%A5"><span class="nav-number">2.</span> <span class="nav-text">正规引入</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83-API"><span class="nav-number"></span> <span class="nav-text">核心 API</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%B0%E8%AE%A1%E5%99%A8"><span class="nav-number"></span> <span class="nav-text">估计器</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">1.</span> <span class="nav-text">线性回归</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#K-%E5%9D%87%E5%80%BC"><span class="nav-number">2.</span> <span class="nav-text">K 均值</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%B0%8F%E7%BB%93"><span class="nav-number">3.</span> <span class="nav-text">小结</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%A2%84%E6%B5%8B%E5%99%A8"><span class="nav-number"></span> <span class="nav-text">预测器</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AF%B9%E7%8E%87%E5%9B%9E%E5%BD%92"><span class="nav-number">1.</span> <span class="nav-text">对率回归</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#K-%E5%9D%87%E5%80%BC-1"><span class="nav-number">2.</span> <span class="nav-text">K 均值</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%B0%8F%E8%8A%82"><span class="nav-number">3.</span> <span class="nav-text">小节</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="草根之明"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">草根之明</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">55</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/justinzm" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;justinzm" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:3907721@qq.com" title="E-Mail → mailto:3907721@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">草根之明</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
